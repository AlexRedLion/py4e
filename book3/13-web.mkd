Uso de Servicios Web
==================

Una vez que recuperar documentos a través de HTTP y analizarlos usando programas
se convirtió en algo sencillo, no se tardó mucho en desarrollar un modelo
consistente en la producción de documentos específicamente diseñados para ser
consumidos por otros programas (es decir, no únicamente HTML para ser mostrado
en un navegador).

Existen dos formatos habituales que se usan para el intercambio de datos a través
de la web. El “eXtensible Markup Language” (lenguaje extensible de marcas), o
XML, ha sido utilizado durante mucho tiempo, y es el más adecuado para intercambiar
datos del tipo documento. Cuando los programas simplemente quieren
intercambiar diccionarios, listas u otra información interna, usan
“JavaScript Object Notation”, o JSON  (Notación de Objetos Javascript; consulta
www.json.org). Nosotros examinaremos ambos formatos.


eXtensible Markup Language - XML
--------------------------------

XML tiene un aspecto similar a HTML, pero más estructurado.
Este es un ejemplo de un documento XML:

~~~~ {.xml}
<person>
  <name>Chuck</name>
  <phone type="intl">
    +1 734 303 4456
  </phone>
  <email hide="yes" />
</person>
~~~~

Cada par de etiquetas de apertura (p. ej., `<person>`) y de cierre
(p. ej., `</person>`) representan un *elemento* o *nodo* con el mismo
nombre de la etiqueta (p. ej., `person`). Cada elemento puede contener
texto, atributos (p. ej., `hide`) y otros elementos anidados. Si un
elemento XML está vacío (es decir, no tiene contenido), puede representarse
con una etiqueta auto-cerrada (p. ej.,  `<email />`).

A menudo resulta útil pensar en un documento XML como en la estructura de un
árbol, donde hay una etiqueta superior (en este caso `person`), y otras etiquetas como
`phone` que se muestran como *hijas* de sus nodos *padres*.

![A Tree Representation of XML](height=2.0in@../images/xml-tree)

Análisis de XML
-----------

\index{ElementTree}
\index{ElementTree!fromstring}
\index{ElementTree!find}

He aquí una aplicación sencilla que analiza un archivo XML y extrae algunos
elementos de él:


\VerbatimInput{../code3/xml1.py} 

Tanto la triple comilla simple (`'''`) como la triple comilla doble (`"""`) permiten la creación de cadenas
que abarquen varias líneas.


La llamada a `fromstring ` convierte la representación de cadena del XML en un
“árbol” de nodos XML. Una vez tenemos el XML como un árbol, disponemos de
una serie de métodos que podemos llamar para extraer porciones de datos de ese
XML. La función `find ` busca a través del árbol XML y recupera el nodo que coincide
con la etiqueta especificada. 

~~~~
Name: Chuck
Attr: yes
~~~~

El usar un analizador de XML como `ElementTree ` tiene la ventaja de que, a pesar
de que el XML de este ejemplo es bastante sencillo, resulta que hay muchas
reglas relativas a la validez del XML, y el uso de `ElementTree ` nos permite
extraer datos del XML sin preocuparnos por esas reglas de sintaxis.

Desplazamiento a través de los nodos
---------------------

\index{ElementTree!findall}
\index{ElementTree!get}

A menudo el XML tiene múltiples nodos y tenemos que escribir un bucle para
procesarlos todos. En el programa siguiente, usamos un bucle para recorrer todos
los nodos `user`:


\VerbatimInput{../code3/xml2.py} 

El método `findall` devuelve una lista de subárboles que representan
las estructuras `user` del árbol XML. A continuación podemos escribir un bucle
`for` que busque en cada uno de los nodos usuario, e imprima el texto de los
elementos `name` e `id`, además del atributo `x` de cada nodo usuario.

~~~~
User count: 2
Name Chuck
Id 001
Attribute 2
Name Brent
Id 009
Attribute 7
~~~~

Es importante incluir todos los elementos base en la declaración de `findall`
exceptuando aquel que se encuentra en el nivel superior (p. ej., `users/user`).
De lo contrario, Python no encontrará ninguno de los nodos que buscamos.

~~~~ {.python}
import xml.etree.ElementTree as ET

input = '''
<stuff>
  <users>
    <user x="2">
      <id>001</id>
      <name>Chuck</name>
    </user>
    <user x="7">
      <id>009</id>
      <name>Brent</name>
    </user>
  </users>
</stuff>'''

stuff = ET.fromstring(input)

lst = stuff.findall('users/user')
print('User count:', len(lst))

lst2 = stuff.findall('user')
print('User count:', len(lst2))
~~~~

`lst` almacena todos los elementos `user` anidados dentro de su base `users`.
`lst2` busca los ementos `user` que no se encuentren anidados dentro del
elemento de nivel superior `stuff` donde no hay ninguno.

~~~~
User count: 2
User count: 0
~~~~

JavaScript Object Notation - JSON
---------------------------------

\index{JSON}
\index{JavaScript Object Notation}

El formato JSON se inspiró en el formato de objetos y arrays que se usa en el
lenguaje JavaScript. Pero como Python se inventó antes que JavaScript, la sintaxis
usada en Python para los diccionarios y listas influyeron la sintaxis de JSON.
De modo que el formato del JSON es casi idéntico a la combinación de listas y
diccionarios de Python.

He aquí una codificación JSON que es más o menos equivalente al XML del ejemplo
anterior:


~~~~ {.json}
{
  "name" : "Chuck",
  "phone" : {
    "type" : "intl",
    "number" : "+1 734 303 4456"
   },
   "email" : {
     "hide" : "yes"
   }
}
~~~~

Si te fijas, encontrarás ciertas diferencias. Primero, en XML se pueden añadir
atributos como “intl” a la etiqueta “phone”. En JSON, simplemente tenemos
parejas clave-valor. Además, la etiqueta “person” de XML ha desaparecido, reemplazada
por un conjunto de llaves exteriores.

En general, las estructuras JSON son más simples que las de XML, debido a que
JSON tiene menos capacidades. Pero JSON tiene la ventaja de que mapea *directamente*
hacia una combinación de diccionarios y listas. Y, dado que casi todos los
lenguajes de programación tienen algo equivalente a los diccionarios y listas de
Python, JSON es un formato muy intuitivo para que dos programas que vayan a
cooperar intercambien datos.

JSON se está convirtiendo rápidamente en el formato elegido para casi todos los
intercambios de datos entre aplicaciones, debido a su relativa simplicidad comparado
con XML.

Análisis de JSON
------------

El JSON se construye anidando diccionarios y listas según se necesite.
En este ejemplo, vamos a representar una lista de usuarios en la que cada usuario
es un conjunto de parejas clave-valor (es decir, un diccionario). De modo que
tendremos una lista de diccionarios.

En el programa siguiente, usaremos la librería integrada `json` para analizar el
JSON y leer los datos. Compáralo cuidadosamente con los datos y código XML
equivalentes que usamos antes. El JSON tiene menos detalles, de modo que podemos
saber de antemano que vamos a obtener una lista y que la lista es de usuarios
y además que cada usuario es un conjunto de parejas clave-valor. El JSON es más
conciso (una ventaja), pero también es menos auto-descriptivo (una desventaja).

\VerbatimInput{../code3/json2.py}

Si comparas el código que extrae los datos del JSON analizado y el del XML, verás
que lo que obtenemos de `json.loads()` es una lista de Python que recorreremos con
un bucle for, y cada elemento dentro de esa lista es un diccionario de Python. Una
vez analizado el JSON, podemos usar el operador índice de Python para extraer
los distintos fragmentos de datos de cada usuario. No tenemos que usar la librería
JSON para rebuscar a través del JSON analizado, ya que los datos devueltos son
sencillamente estructuras nativas de Python.

La salida de este programa es exactamente la misma que la de la versión XML
anterior.

~~~~
User count: 2
Name Chuck
Id 001
Attribute 2
Name Brent
Id 009
Attribute 7
~~~~

En general, hay una tendencia en la industria a apartarse del XML y pasar al
JSON para los servicios web. Como el JSON es más sencillo, y se mapea de forma
más directa hacia estructuras de datos nativas que ya tenemos en los lenguajes de
programación, el código de análisis y extracción de datos normalmente es más
sencillo y directo usando JSON. Sin embargo, XML es más auto-descriptivo, y por
eso hay ciertas aplicaciones en las cuales mantiene su ventaja. Por ejemplo,
la mayoría de los procesadores de texto almacenan sus documentos internamente
usando XML en vez de JSON.

Interfaces de programación de aplicaciones
----------------------------------

Ahora tenemos la capacidad de intercambiar datos entre aplicaciones usando el
Protocolo de Transporte de Hipertexto (HTTP), y un modo de representar estructuras
de datos complejas para poder enviar y recibir los datos entre esas aplicaciones,
a través del eXtensibleMarkup Language (XML) o del JavaScript Object Notation (JSON).

El paso siguiente es empezar a definir y documentar “contratos” entre
aplicaciones usando estas técnicas. El nombre habitual para estos contratos entre
aplicaciones es *Interfaces de Programación de Aplicaciones* (Application
Program Interfaces), o APIs. Cuando se utiliza una API, normalmente un programa
crea un conjunto de *servicios* disponibles para que los usen otras aplicaciones
y publica las APIs (es decir, las “reglas”) que deben ser seguidas para acceder
a los servicios proporcionados por el programa.

When we begin to build our programs where the functionality of our
program includes access to services provided by other programs, we call
the approach a *Service-oriented architecture* (SOA). A
SOA approach is one where our overall application makes use of the
services of other applications. A non-SOA approach is where the
application is a single standalone application which contains all of the
code necessary to implement the application.

We see many examples of SOA when we use the web. We can go to a single
web site and book air travel, hotels, and automobiles all from a single
site. The data for hotels is not stored on the airline computers.
Instead, the airline computers contact the services on the hotel
computers and retrieve the hotel data and present it to the user. When
the user agrees to make a hotel reservation using the airline site, the
airline site uses another web service on the hotel systems to actually
make the reservation. And when it comes time to charge your credit card
for the whole transaction, still other computers become involved in the
process.

![Service-oriented architecture](height=3.0in@../images/soa)

A Service-oriented architecture has many advantages, including: (1) we
always maintain only one copy of data (this is particularly important
for things like hotel reservations where we do not want to over-commit)
and (2) the owners of the data can set the rules about the use of their
data. With these advantages, an SOA system must be carefully designed to
have good performance and meet the user's needs.

When an application makes a set of services in its API available over
the web, we call these *web services*.

Security and API usage
----------------------

\index{OAuth}
\index{API!key}

It is quite common that you need an API key to make use of a
vendor's API. The general idea is that they want to know who is using
their services and how much each user is using. Perhaps they have free
and pay tiers of their services or have a policy that limits the number
of requests that a single individual can make during a particular time
period.

Sometimes once you get your API key, you simply include the key as part
of POST data or perhaps as a parameter on the URL when calling the API.

Other times, the vendor wants increased assurance of the source of the
requests and so they expect you to send cryptographically signed
messages using shared keys and secrets. A very common technology that is
used to sign requests over the Internet is called
*OAuth*. You can read more about the OAuth protocol at
[www.oauth.net](http://www.oauth.net).

Thankfully there are a number of convenient
and free OAuth libraries so you can avoid writing an OAuth
implementation from scratch by reading the specification. These
libraries are of varying complexity and have varying degrees of
richness. The OAuth web site has information about various OAuth
libraries.

Glossary
--------

API
:   Application Program Interface - A contract between applications that
    defines the patterns of interaction between two application
    components.
\index{API}

ElementTree
:   A built-in Python library used to parse XML data.
\index{ElementTree}

JSON
:   JavaScript Object Notation. A format that allows for the markup of
    structured data based on the syntax of JavaScript Objects.
\index{JSON}
\index{JavaScript Object Notation}

SOA
:   Service-Oriented Architecture. When an application is made of
    components connected across a network.
\index{SOA}
\index{Service Oriented Architecture}

XML
:   eXtensible Markup Language. A format that allows for the markup of
    structured data.
\index{XML}
\index{eXtensible Markup Language}

Application 1: Google geocoding web service
----------------------------

\index{Google}
\index{geocoding}
\index{web service}

Google has an excellent web service that allows us to make use of their
large database of geographic information. We can submit a geographical
search string like "Ann Arbor, MI" to their geocoding API and have
Google return its best guess as to where on a map we might find our
search string and tell us about the landmarks nearby.

The geocoding service is free but rate limited so you cannot make
unlimited use of the API in a commercial application. But if you have
some survey data where an end user has entered a location in a
free-format input box, you can use this API to clean up your data quite
nicely.

*When you are using a free API like Google's geocoding API, you
need to be respectful in your use of these resources. If too many people
abuse the service, Google might drop or significantly curtail its free
service.*

\index{rate limiting}

You can read the online documentation for this service, but it is quite
simple and you can even test it using a browser by typing the following
URL into your browser:

[http://maps.googleapis.com/maps/api/geocode/json?address=Ann+Arbor%2C+MI](http://maps.googleapis.com/maps/api/geocode/json?address=Ann+Arbor%2C+MI)

Make sure to unwrap the URL and remove any spaces from the URL before
pasting it into your browser.

The following is a simple application to prompt the user for a search
string, call the Google geocoding API, and extract information from the
returned JSON.

\VerbatimInput{../code3/geojson.py} 

The program takes the search string and constructs a URL with the search
string as a properly encoded parameter and then uses
`urllib` to retrieve the text from the Google geocoding
API. Unlike a fixed web page, the data we get depends on the parameters
we send and the geographical data stored in Google's servers.

Once we retrieve the JSON data, we parse it with the
`json` library and do a few checks to make sure that we
received good data, then extract the information that we are looking
for.

The output of the program is as follows (some of the returned JSON has
been removed):

~~~~
$ python3 geojson.py 
Enter location: Ann Arbor, MI
Retrieving http://py4e-data.dr-chuck.net/json?address=Ann+Arbor%2C+MI&key=42
Retrieved 1736 characters
~~~~

~~~~ {.json}
{
    "results": [
        {
            "address_components": [
                {
                    "long_name": "Ann Arbor",
                    "short_name": "Ann Arbor",
                    "types": [
                        "locality",
                        "political"
                    ]
                },
                {
                    "long_name": "Washtenaw County",
                    "short_name": "Washtenaw County",
                    "types": [
                        "administrative_area_level_2",
                        "political"
                    ]
                },
                {
                    "long_name": "Michigan",
                    "short_name": "MI",
                    "types": [
                        "administrative_area_level_1",
                        "political"
                    ]
                },
                {
                    "long_name": "United States",
                    "short_name": "US",
                    "types": [
                        "country",
                        "political"
                    ]
                }
            ],
            "formatted_address": "Ann Arbor, MI, USA",
            "geometry": {
                "bounds": {
                    "northeast": {
                        "lat": 42.3239728,
                        "lng": -83.6758069
                    },
                    "southwest": {
                        "lat": 42.222668,
                        "lng": -83.799572
                    }
                },
                "location": {
                    "lat": 42.2808256,
                    "lng": -83.7430378
                },
                "location_type": "APPROXIMATE",
                "viewport": {
                    "northeast": {
                        "lat": 42.3239728,
                        "lng": -83.6758069
                    },
                    "southwest": {
                        "lat": 42.222668,
                        "lng": -83.799572
                    }
                }
            },
            "place_id": "ChIJMx9D1A2wPIgR4rXIhkb5Cds",
            "types": [
                "locality",
                "political"
            ]
        }
    ],
    "status": "OK"
}
lat 42.2808256 lng -83.7430378
Ann Arbor, MI, USA
~~~~

~~~~
Enter location:
~~~~

You can download
[www.py4e.com/code3/geoxml.py](http://www.py4e.com/code3/geoxml.py) to
explore the XML variant of the Google geocoding API.

**Exercise 1: Change either**
[**geojson.py**](http://www.py4e.com/code3/geojson.py) **or**
[**geoxml.py**](http://www.py4e.com/code3/geoxml.py)
**to print out the two-character country code from the retrieved data.
Add error checking so your program does not traceback if the country
code is not there. Once you have it working, search for
"Atlantic Ocean" and make sure it can handle locations
that are not in any country.**

Application 2: Twitter
----------------------

As the Twitter API became increasingly valuable, Twitter went from an
open and public API to an API that required the use of OAuth signatures
on each API request. 

For this next sample program, download the files
*twurl.py*, *hidden.py*, *oauth.py*, and *twitter1.py* from
[www.py4e.com/code](http://www.py4e.com/code3)
and put them all in a folder on your computer.

To make use of these programs you will need to have a Twitter account,
and authorize your Python code as an application, set up a key, secret,
token and token secret. You will edit the file
*hidden.py* and put these four strings into the
appropriate variables in the file:

\VerbatimInput{../code3/hidden.py} 

The Twitter web service are accessed using a URL like this:

<https://api.twitter.com/1.1/statuses/user_timeline.json>

But once all of the security information has been added, the URL will
look more like:

~~~~
https://api.twitter.com/1.1/statuses/user_timeline.json?count=2
&oauth_version=1.0&oauth_token=101...SGI&screen_name=drchuck
&oauth_nonce=09239679&oauth_timestamp=1380395644
&oauth_signature=rLK...BoD&oauth_consumer_key=h7Lu...GNg
&oauth_signature_method=HMAC-SHA1
~~~~

You can read the OAuth specification if you want to know more about the
meaning of the various parameters that are added to meet the security
requirements of OAuth.

For the programs we run with Twitter, we hide all the complexity in the
files *oauth.py* and *twurl.py*. We simply
set the secrets in *hidden.py* and then send the desired
URL to the *twurl.augment()* function and the library
code adds all the necessary parameters to the URL for us.

This program retrieves the timeline for a
particular Twitter user and returns it to us in JSON format in a string.
We simply print the first 250 characters of the string:

\VerbatimInput{../code3/twitter1.py} 
\begin{trinketfiles}
../code3/twurl.py
\end{trinketfiles}

When the program runs it produces the following output:

~~~~
Enter Twitter Account:drchuck
Retrieving https://api.twitter.com/1.1/ ...
[{"created_at":"Sat Sep 28 17:30:25 +0000 2013","
id":384007200990982144,"id_str":"384007200990982144",
"text":"RT @fixpert: See how the Dutch handle traffic
intersections: http:\/\/t.co\/tIiVWtEhj4\n#brilliant",
"source":"web","truncated":false,"in_rep
Remaining 178

Enter Twitter Account:fixpert
Retrieving https://api.twitter.com/1.1/ ...
[{"created_at":"Sat Sep 28 18:03:56 +0000 2013",
"id":384015634108919808,"id_str":"384015634108919808",
"text":"3 months after my freak bocce ball accident,
my wedding ring fits again! :)\n\nhttps:\/\/t.co\/2XmHPx7kgX",
"source":"web","truncated":false,
Remaining 177

Enter Twitter Account:
~~~~

Along with the returned timeline data, Twitter also returns metadata
about the request in the HTTP response headers. One header in
particular, `x-rate-limit-remaining`, informs us how many
more requests we can make before we will be shut off for a short time
period. You can see that our remaining retrievals drop by one each time
we make a request to the API.

In the following example, we retrieve a user's Twitter friends, parse
the returned JSON, and extract some of the information about the
friends. We also dump the JSON after parsing and "pretty-print" it with
an indent of four characters to allow us to pore through the data when
we want to extract more fields.

\VerbatimInput{../code3/twitter2.py} 
\begin{trinketfiles}
../code3/twurl.py
\end{trinketfiles}

Since the JSON becomes a set of nested Python lists and dictionaries, we
can use a combination of the index operation and `for` loops
to wander through the returned data structures with very little Python
code.

The output of the program looks as follows (some of the data items are
shortened to fit on the page):

~~~~
Enter Twitter Account:drchuck
Retrieving https://api.twitter.com/1.1/friends ...
Remaining 14
~~~~

~~~~ {.json}
{
  "next_cursor": 1444171224491980205,
  "users": [
    {
      "id": 662433,
      "followers_count": 28725,
      "status": {
        "text": "@jazzychad I just bought one .__.",
        "created_at": "Fri Sep 20 08:36:34 +0000 2013",
        "retweeted": false,
      },
      "location": "San Francisco, California",
      "screen_name": "leahculver",
      "name": "Leah Culver",
    },
    {
      "id": 40426722,
      "followers_count": 2635,
      "status": {
        "text": "RT @WSJ: Big employers like Google ...",
        "created_at": "Sat Sep 28 19:36:37 +0000 2013",
      },
      "location": "Victoria Canada",
      "screen_name": "_valeriei",
      "name": "Valerie Irvine",
    }
  ],
 "next_cursor_str": "1444171224491980205"
}
~~~~

~~~~
leahculver
   @jazzychad I just bought one .__.
_valeriei
   RT @WSJ: Big employers like Google, AT&amp;T are h
ericbollens
   RT @lukew: sneak peek: my LONG take on the good &a
halherzog
   Learning Objects is 10. We had a cake with the LO,
scweeker
   @DeviceLabDC love it! Now where so I get that "etc

Enter Twitter Account:
~~~~

The last bit of the output is where we see the for loop reading the five
most recent "friends" of the *@drchuck* Twitter account
and printing the most recent status for each friend. There is a great
deal more data available in the returned JSON. If you look in the output
of the program, you can also see that the "find the friends" of a
particular account has a different rate limitation than the number of
timeline queries we are allowed to run per time period.

These secure API keys allow Twitter to have solid confidence that they
know who is using their API and data and at what level. The
rate-limiting approach allows us to do simple, personal data retrievals
but does not allow us to build a product that pulls data from their API
millions of times per day.


